{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets download\n",
    "\n",
    "Requires [Kaggle API](https://www.kaggle.com/docs/api#authentication) token in one of these directories:\n",
    "```\n",
    "~/.kaggle/kaggle.json\n",
    "\n",
    "~/.config/kaggle/kaggle.json\n",
    "```\n",
    "\n",
    "Used datasets:\n",
    "- [Main OSes terminal commands](https://www.kaggle.com/datasets/vaibhavdlights/linuxcmdmacos-commands)\n",
    "- [Wikipedia sentences](https://www.kaggle.com/datasets/mikeortman/wikipedia-sentences)\n",
    "- [Wikipedia plaintext 2023](https://www.kaggle.com/datasets/jjinho/wikipedia-20230701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jakubpiasek/.cache/kagglehub/datasets/vaibhavdlights/linuxcmdmacos-commands/versions/1\n",
      "/home/jakubpiasek/.cache/kagglehub/datasets/mikeortman/wikipedia-sentences/versions/3\n"
     ]
    }
   ],
   "source": [
    "# Data storage\n",
    "subprocess.run([\"mkdir\", \"data\"])\n",
    "\n",
    "# CLI commands dataset\n",
    "pathCommands = kagglehub.dataset_download(\"vaibhavdlights/linuxcmdmacos-commands\")\n",
    "subprocess.run([\"mv\", pathCommands, \"./data/commands/\"])\n",
    "\n",
    "\n",
    "# Wikipedia sentences dataset\n",
    "pathWiki = kagglehub.dataset_download(\"mikeortman/wikipedia-sentences\")\n",
    "subprocess.run([\"mv\", pathWiki, \"./data/wikisen/\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Removing punctuation and formatting the text so it's only plain text for unsupervised learning\n",
    "\n",
    "General dataset and training/test splits preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining data frames\n",
    "linuxCommandsDf = pd.read_csv('data/commands/linux_commands.csv')\n",
    "cmdCommandsDf = pd.read_csv('data/commands/cmd_commands.csv')\n",
    "macOsCommandsDf = pd.read_csv('data/commands/macos_commands.csv')\n",
    "vbscriptCommandsDf = pd.read_csv('data/commands/vbscript_commands.csv')\n",
    "\n",
    "commandsDf = pd.concat([linuxCommandsDf, cmdCommandsDf, macOsCommandsDf, vbscriptCommandsDf], ignore_index = True)\n",
    "\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "# Removing duplicate columns (indexes)\n",
    "commandsDf = commandsDf.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Removing unwanted parts of strings\n",
    "commandsDf['description'] = commandsDf['description'].str.replace(' •', '')\n",
    "commandsDf['description'] = commandsDf['description'].str.replace('•', '')\n",
    "\n",
    "# Saving the data frame to plain text file\n",
    "commandsDf.to_csv('data/commandsDf.txt', sep='\\t', index=False, header=False)\n",
    "\n",
    "\n",
    "# Joining text files\n",
    "data = data2 = \"\"\n",
    "\n",
    "with open('data/commandsDf.txt') as fileWrite:\n",
    "    data = fileWrite.read()\n",
    "\n",
    "with open('data/wikisen/wikisent2.txt') as fileWrite:\n",
    "    data2 = fileWrite.read()\n",
    "\n",
    "data += data2\n",
    "\n",
    "with open ('data/data.txt', 'w') as fileWrite:\n",
    "    fileWrite.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training word vectors\n",
    "\n",
    "Word representation\n",
    "\n",
    "Data split - 80% training 20% test\n",
    "\n",
    "CBOW vs skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 127M words\n",
      "Number of words:  486699\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   52007 lr:  0.000000 avg.loss:  0.485565 ETA:   0h 0m 0s53s  70494 lr:  0.048440 avg.loss:  1.697119 ETA:   0h20m51s  70493 lr:  0.048086 avg.loss:  1.669816 ETA:   0h20m42s  6.6% words/sec/thread:   69553 lr:  0.046714 avg.loss:  1.605509 ETA:   0h20m23s 1.518650 ETA:   0h19m50s 0.045232 avg.loss:  1.483721 ETA:   0h19m42s 10.2% words/sec/thread:   69605 lr:  0.044902 avg.loss:  1.464940 ETA:   0h19m35s lr:  0.043324 avg.loss:  1.413436 ETA:   0h18m55s 13.6% words/sec/thread:   69489 lr:  0.043212 avg.loss:  1.411198 ETA:   0h18m52s 1.410845 ETA:   0h18m52s 13.6% words/sec/thread:   69462 lr:  0.043187 avg.loss:  1.410705 ETA:   0h18m52s 14.2% words/sec/thread:   69289 lr:  0.042906 avg.loss:  1.405271 ETA:   0h18m48s 18.9% words/sec/thread:   67672 lr:  0.040567 avg.loss:  1.279591 ETA:   0h18m12ss 0.040246 avg.loss:  1.247219 ETA:   0h18m 7s 1.210666 ETA:   0h18m 2s 0.039320 avg.loss:  1.162335 ETA:   0h17m56s ETA:   0h17m54s ETA:   0h17m54s 22.6% words/sec/thread:   65976 lr:  0.038703 avg.loss:  1.127338 ETA:   0h17m48s ETA:   0h17m48s  0h17m42s 25.5% words/sec/thread:   64810 lr:  0.037227 avg.loss:  1.066986 ETA:   0h17m26s avg.loss:  1.038939 ETA:   0h17m17s 27.3% words/sec/thread:   64189 lr:  0.036337 avg.loss:  1.018264 ETA:   0h17m11ssh16m31s 33.3% words/sec/thread:   62267 lr:  0.033337 avg.loss:  0.894739 ETA:   0h16m15s 33.4% words/sec/thread:   62241 lr:  0.033289 avg.loss:  0.893769 ETA:   0h16m14s words/sec/thread:   61728 lr:  0.032324 avg.loss:  0.863160 ETA:   0h15m54sh15m40s15m28s 38.6% words/sec/thread:   60921 lr:  0.030711 avg.loss:  0.815399 ETA:   0h15m18s avg.loss:  0.762240 ETA:   0h14m30ss 0.738798 ETA:   0h14m 2s 46.2% words/sec/thread:   59214 lr:  0.026907 avg.loss:  0.727757 ETA:   0h13m47sh13m42s ETA:   0h13m23s ETA:   0h12m49s% words/sec/thread:   58102 lr:  0.023764 avg.loss:  0.676679 ETA:   0h12m25sm53sh11m20sm15s  56930 lr:  0.021044 avg.loss:  0.644420 ETA:   0h11m13s ETA:   0h10m56s ETA:   0h10m44s words/sec/thread:   56321 lr:  0.019037 avg.loss:  0.622608 ETA:   0h10m15s 63.4% words/sec/thread:   56091 lr:  0.018284 avg.loss:  0.618116 ETA:   0h 9m53s lr:  0.017905 avg.loss:  0.615899 ETA:   0h 9m42s 64.4% words/sec/thread:   55961 lr:  0.017811 avg.loss:  0.615349 ETA:   0h 9m39s ETA:   0h 9m37s 0.612368 ETA:   0h 9m24s 66.0% words/sec/thread:   55730 lr:  0.016990 avg.loss:  0.610683 ETA:   0h 9m15s lr:  0.016915 avg.loss:  0.610262 ETA:   0h 9m13s 66.6% words/sec/thread:   55640 lr:  0.016678 avg.loss:  0.608946 ETA:   0h 9m 6s words/sec/thread:   55579 lr:  0.016448 avg.loss:  0.607676 ETA:   0h 8m59s avg.loss:  0.604333 ETA:   0h 8m40s 8m20s 71.3% words/sec/thread:   55063 lr:  0.014347 avg.loss:  0.596554 ETA:   0h 7m54s 71.7% words/sec/thread:   55015 lr:  0.014174 avg.loss:  0.595666 ETA:   0h 7m49s 73.5% words/sec/thread:   54804 lr:  0.013243 avg.loss:  0.591006 ETA:   0h 7m20sm34s 0.581255 ETA:   0h 6m23s lr:  0.011266 avg.loss:  0.580384 ETA:   0h 6m17sm14sh 5m52s 5m32s% words/sec/thread:   53916 lr:  0.009426 avg.loss:  0.568778 ETA:   0h 5m18s 0.559101 ETA:   0h 4m37s avg.loss:  0.554105 ETA:   0h 4m10s avg.loss:  0.553368 ETA:   0h 4m 7s 85.8% words/sec/thread:   53389 lr:  0.007100 avg.loss:  0.552198 ETA:   0h 4m 2ss 88.0% words/sec/thread:   53140 lr:  0.005988 avg.loss:  0.544247 ETA:   0h 3m25s  53088 lr:  0.005747 avg.loss:  0.542587 ETA:   0h 3m17s% words/sec/thread:   53084 lr:  0.005727 avg.loss:  0.542457 ETA:   0h 3m16s  53080 lr:  0.005707 avg.loss:  0.542322 ETA:   0h 3m15s avg.loss:  0.536707 ETA:   0h 2m46s 90.4% words/sec/thread:   52907 lr:  0.004788 avg.loss:  0.536353 ETA:   0h 2m44ss 92.9% words/sec/thread:   52646 lr:  0.003528 avg.loss:  0.521187 ETA:   0h 2m 2sm 1s% words/sec/thread:   52619 lr:  0.003404 avg.loss:  0.520222 ETA:   0h 1m57s% words/sec/thread:   52599 lr:  0.003296 avg.loss:  0.518784 ETA:   0h 1m54s 0.003119 avg.loss:  0.516444 ETA:   0h 1m48s avg.loss:  0.515993 ETA:   0h 1m46s 94.5% words/sec/thread:   52491 lr:  0.002742 avg.loss:  0.511570 ETA:   0h 1m35s  52457 lr:  0.002544 avg.loss:  0.509016 ETA:   0h 1m28s 0.002130 avg.loss:  0.503749 ETA:   0h 1m14s avg.loss:  0.492546 ETA:   0h 0m37s 0m31s% words/sec/thread:   52106 lr:  0.000629 avg.loss:  0.489686 ETA:   0h 0m21s words/sec/thread:   52062 lr:  0.000366 avg.loss:  0.487864 ETA:   0h 0m12s 99.3% words/sec/thread:   52058 lr:  0.000358 avg.loss:  0.487787 ETA:   0h 0m12s 99.3% words/sec/thread:   52052 lr:  0.000334 avg.loss:  0.487648 ETA:   0h 0m11s lr:  0.000033 avg.loss:  0.485772 ETA:   0h 0m 1s\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "\n",
    "with open('data/data.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Saving the split data to new files\n",
    "with open('data/train_data.txt', 'w') as train_file:\n",
    "    train_file.writelines(train_data)\n",
    "\n",
    "with open('data/test_data.txt', 'w') as test_file:\n",
    "    test_file.writelines(test_data)\n",
    "\n",
    "# TODO zostawic commandsDf.txt w train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 127M words\n",
      "Number of words:  486699\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   99146 lr:  0.000000 avg.loss:  1.046694 ETA:   0h 0m 0s lr:  0.047926 avg.loss:  1.859780 ETA:   0h 9m40s 9m27s words/sec/thread:  149067 lr:  0.046768 avg.loss:  1.750912 ETA:   0h 9m31s32s 16.2% words/sec/thread:  145456 lr:  0.041901 avg.loss:  1.568963 ETA:   0h 8m44s avg.loss:  1.555797 ETA:   0h 8m44s% words/sec/thread:  134246 lr:  0.038837 avg.loss:  1.503370 ETA:   0h 8m47s 0.038825 avg.loss:  1.502928 ETA:   0h 8m47s avg.loss:  1.473101 ETA:   0h 8m46s% words/sec/thread:  123724 lr:  0.034045 avg.loss:  1.394181 ETA:   0h 8m21s words/sec/thread:  122907 lr:  0.033567 avg.loss:  1.385990 ETA:   0h 8m17s 122863 lr:  0.033545 avg.loss:  1.385620 ETA:   0h 8m17s 121384 lr:  0.032575 avg.loss:  1.370889 ETA:   0h 8m 8s 41.5% words/sec/thread:  117372 lr:  0.029262 avg.loss:  1.327538 ETA:   0h 7m34s 0.029032 avg.loss:  1.321859 ETA:   0h 7m32s22s ETA:   0h 7m19s% words/sec/thread:  113714 lr:  0.026238 avg.loss:  1.260349 ETA:   0h 7m 0s avg.loss:  1.257471 ETA:   0h 6m57s 113204 lr:  0.025695 avg.loss:  1.254839 ETA:   0h 6m53s 1.240142 ETA:   0h 6m26s 56.4% words/sec/thread:  109972 lr:  0.021819 avg.loss:  1.227172 ETA:   0h 6m 1s words/sec/thread:  108695 lr:  0.019942 avg.loss:  1.197230 ETA:   0h 5m34s% words/sec/thread:  107545 lr:  0.018140 avg.loss:  1.175120 ETA:   0h 5m 7s 1.151955 ETA:   0h 4m26s 0.014834 avg.loss:  1.148549 ETA:   0h 4m15s 72.4% words/sec/thread:  105232 lr:  0.013824 avg.loss:  1.143487 ETA:   0h 3m59s% words/sec/thread:  105205 lr:  0.013769 avg.loss:  1.143209 ETA:   0h 3m58s 73.8% words/sec/thread:  104888 lr:  0.013120 avg.loss:  1.140018 ETA:   0h 3m47s lr:  0.011718 avg.loss:  1.133122 ETA:   0h 3m24s19ss 91.5% words/sec/thread:  101314 lr:  0.004270 avg.loss:  1.079575 ETA:   0h 1m16s 1.073781 ETA:   0h 1m 2s 0m49s 0m41s 95.7% words/sec/thread:  100285 lr:  0.002154 avg.loss:  1.063724 ETA:   0h 0m39s% words/sec/thread:   99491 lr:  0.000564 avg.loss:  1.051732 ETA:   0h 0m10sm 6s words/sec/thread:   99288 lr:  0.000258 avg.loss:  1.049488 ETA:   0h 0m 4ss% words/sec/thread:   99208 lr:  0.000123 avg.loss:  1.048078 ETA:   0h 0m 2s\n",
      "Read 127M words\n",
      "Number of words:  486699\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   47848 lr:  0.000000 avg.loss:  0.522624 ETA:   0h 0m 0s avg.loss:  4.110000 ETA:   0h27m22s  0.4% words/sec/thread:   55928 lr:  0.049809 avg.loss:  2.073396 ETA:   0h27m 2s13s words/sec/thread:   53016 lr:  0.047823 avg.loss:  1.669444 ETA:   0h27m23sh27m29s words/sec/thread:   52099 lr:  0.047273 avg.loss:  1.647591 ETA:   0h27m33s% words/sec/thread:   51496 lr:  0.046690 avg.loss:  1.614091 ETA:   0h27m31s27m32s ETA:   0h27m24s% words/sec/thread:   51091 lr:  0.046008 avg.loss:  1.590055 ETA:   0h27m20ssm10s  9.5% words/sec/thread:   50659 lr:  0.045261 avg.loss:  1.539399 ETA:   0h27m 7s words/sec/thread:   50582 lr:  0.044830 avg.loss:  1.519027 ETA:   0h26m54s26m30s lr:  0.043628 avg.loss:  1.462606 ETA:   0h26m24s 13.3% words/sec/thread:   50085 lr:  0.043338 avg.loss:  1.453872 ETA:   0h26m16s% words/sec/thread:   50140 lr:  0.042976 avg.loss:  1.439367 ETA:   0h26m 1s 1.433340 ETA:   0h25m54s words/sec/thread:   50208 lr:  0.042760 avg.loss:  1.430471 ETA:   0h25m51s 0.042567 avg.loss:  1.425419 ETA:   0h25m43s  0h25m13s lr:  0.041330 avg.loss:  1.380924 ETA:   0h24m50s 0.041194 avg.loss:  1.376441 ETA:   0h24m44s  50534 lr:  0.040324 avg.loss:  1.354543 ETA:   0h24m13s% words/sec/thread:   50527 lr:  0.040284 avg.loss:  1.353963 ETA:   0h24m12s 19.7% words/sec/thread:   50542 lr:  0.040172 avg.loss:  1.352491 ETA:   0h24m 8s24m 6s% words/sec/thread:   50709 lr:  0.039392 avg.loss:  1.282533 ETA:   0h23m35s 22.9% words/sec/thread:   50826 lr:  0.038569 avg.loss:  1.201008 ETA:   0h23m 2s 1.155733 ETA:   0h22m28s  50686 lr:  0.037208 avg.loss:  1.128333 ETA:   0h22m17s 26.4% words/sec/thread:   50648 lr:  0.036790 avg.loss:  1.098614 ETA:   0h22m 3sh21m59s 26.7% words/sec/thread:   50636 lr:  0.036673 avg.loss:  1.091020 ETA:   0h21m59s 26.7% words/sec/thread:   50635 lr:  0.036667 avg.loss:  1.090829 ETA:   0h21m59s 28.6% words/sec/thread:   50700 lr:  0.035725 avg.loss:  1.051851 ETA:   0h21m23s 29.2% words/sec/thread:   50712 lr:  0.035381 avg.loss:  1.036095 ETA:   0h21m11s lr:  0.034998 avg.loss:  1.014108 ETA:   0h20m57s lr:  0.034577 avg.loss:  0.992216 ETA:   0h20m42s lr:  0.032516 avg.loss:  0.912222 ETA:   0h19m34sm26s  50306 lr:  0.031679 avg.loss:  0.893365 ETA:   0h19m 7s 0.892936 ETA:   0h19m 6s 36.9% words/sec/thread:   50290 lr:  0.031570 avg.loss:  0.891220 ETA:   0h19m 3s% words/sec/thread:   50281 lr:  0.031521 avg.loss:  0.890234 ETA:   0h19m 2s 0.887628 ETA:   0h18m57s ETA:   0h18m56s18m55s ETA:   0h18m45ss 39.3% words/sec/thread:   50045 lr:  0.030361 avg.loss:  0.864361 ETA:   0h18m25s words/sec/thread:   50036 lr:  0.030137 avg.loss:  0.857050 ETA:   0h18m17s avg.loss:  0.838707 ETA:   0h17m50s words/sec/thread:   50099 lr:  0.029342 avg.loss:  0.837216 ETA:   0h17m47s% words/sec/thread:   50150 lr:  0.028781 avg.loss:  0.828595 ETA:   0h17m25s 42.6% words/sec/thread:   50159 lr:  0.028682 avg.loss:  0.827108 ETA:   0h17m21s 43.2% words/sec/thread:   50160 lr:  0.028421 avg.loss:  0.823193 ETA:   0h17m12s 0.817224 ETA:   0h17m 3s avg.loss:  0.810374 ETA:   0h16m54ss 45.8% words/sec/thread:   49912 lr:  0.027124 avg.loss:  0.790809 ETA:   0h16m30s 47.0% words/sec/thread:   49875 lr:  0.026487 avg.loss:  0.776404 ETA:   0h16m 7s  0h15m54s  49741 lr:  0.025639 avg.loss:  0.759219 ETA:   0h15m39s 49.7% words/sec/thread:   49635 lr:  0.025147 avg.loss:  0.751842 ETA:   0h15m23s words/sec/thread:   49632 lr:  0.025110 avg.loss:  0.751449 ETA:   0h15m21s 0.751339 ETA:   0h15m21ss 51.6% words/sec/thread:   49547 lr:  0.024179 avg.loss:  0.737107 ETA:   0h14m49s ETA:   0h14m29sh14m28s 0.023469 avg.loss:  0.725238 ETA:   0h14m24s 0.723043 ETA:   0h14m20s% words/sec/thread:   49392 lr:  0.022882 avg.loss:  0.718154 ETA:   0h14m 4s 57.4% words/sec/thread:   49189 lr:  0.021313 avg.loss:  0.697869 ETA:   0h13m 9s 58.2% words/sec/thread:   49164 lr:  0.020882 avg.loss:  0.694225 ETA:   0h12m53s lr:  0.020757 avg.loss:  0.693157 ETA:   0h12m49s 58.9% words/sec/thread:   49127 lr:  0.020545 avg.loss:  0.690283 ETA:   0h12m41s 0.020504 avg.loss:  0.689672 ETA:   0h12m40s 0.681981 ETA:   0h12m20s 62.3% words/sec/thread:   49062 lr:  0.018832 avg.loss:  0.667702 ETA:   0h11m39s% words/sec/thread:   48972 lr:  0.018539 avg.loss:  0.663564 ETA:   0h11m29s words/sec/thread:   48923 lr:  0.018364 avg.loss:  0.661167 ETA:   0h11m23s words/sec/thread:   48849 lr:  0.018200 avg.loss:  0.659676 ETA:   0h11m18s 64.0% words/sec/thread:   48795 lr:  0.018013 avg.loss:  0.658089 ETA:   0h11m12s% words/sec/thread:   48698 lr:  0.017711 avg.loss:  0.655159 ETA:   0h11m 2s  48683 lr:  0.017696 avg.loss:  0.654988 ETA:   0h11m 2s avg.loss:  0.654089 ETA:   0h10m59s 64.8% words/sec/thread:   48619 lr:  0.017596 avg.loss:  0.654056 ETA:   0h10m59s% words/sec/thread:   48585 lr:  0.017497 avg.loss:  0.653327 ETA:   0h10m56s 65.0% words/sec/thread:   48582 lr:  0.017488 avg.loss:  0.653272 ETA:   0h10m55s 65.1% words/sec/thread:   48580 lr:  0.017471 avg.loss:  0.653153 ETA:   0h10m55s% words/sec/thread:   48570 lr:  0.016454 avg.loss:  0.646299 ETA:   0h10m17sh10m10s 0.016207 avg.loss:  0.643175 ETA:   0h10m 8ss  48412 lr:  0.014491 avg.loss:  0.626563 ETA:   0h 9m 5s 0.013354 avg.loss:  0.617473 ETA:   0h 8m22s% words/sec/thread:   48445 lr:  0.012740 avg.loss:  0.614117 ETA:   0h 7m59s lr:  0.012571 avg.loss:  0.613143 ETA:   0h 7m52s 0.012014 avg.loss:  0.609033 ETA:   0h 7m32s 0.011299 avg.loss:  0.603482 ETA:   0h 7m 5s lr:  0.010572 avg.loss:  0.596922 ETA:   0h 6m38s avg.loss:  0.596023 ETA:   0h 6m31s 79.3% words/sec/thread:   48325 lr:  0.010373 avg.loss:  0.595847 ETA:   0h 6m31s words/sec/thread:   48326 lr:  0.010082 avg.loss:  0.594363 ETA:   0h 6m20s words/sec/thread:   48326 lr:  0.009982 avg.loss:  0.593901 ETA:   0h 6m16s 80.2% words/sec/thread:   48322 lr:  0.009903 avg.loss:  0.593508 ETA:   0h 6m13s 6m11s 81.6% words/sec/thread:   48277 lr:  0.009191 avg.loss:  0.589428 ETA:   0h 5m46s  0h 5m15s 0.580389 ETA:   0h 4m59s words/sec/thread:   48165 lr:  0.007752 avg.loss:  0.578853 ETA:   0h 4m53s 4m30s  48098 lr:  0.007128 avg.loss:  0.574283 ETA:   0h 4m29s 0.006939 avg.loss:  0.572936 ETA:   0h 4m22s% words/sec/thread:   48084 lr:  0.006849 avg.loss:  0.572198 ETA:   0h 4m19s 87.4% words/sec/thread:   48066 lr:  0.006320 avg.loss:  0.567880 ETA:   0h 3m59s 87.5% words/sec/thread:   48068 lr:  0.006241 avg.loss:  0.567247 ETA:   0h 3m56s 88.9% words/sec/thread:   48058 lr:  0.005549 avg.loss:  0.562004 ETA:   0h 3m30s 89.1% words/sec/thread:   48040 lr:  0.005434 avg.loss:  0.561508 ETA:   0h 3m26s ETA:   0h 3m24s% words/sec/thread:   48022 lr:  0.005112 avg.loss:  0.559878 ETA:   0h 3m13s 90.4% words/sec/thread:   48006 lr:  0.004807 avg.loss:  0.557994 ETA:   0h 3m 2s 90.5% words/sec/thread:   47998 lr:  0.004735 avg.loss:  0.557700 ETA:   0h 2m59sh 2m45s 0.552445 ETA:   0h 2m12s56s% words/sec/thread:   47951 lr:  0.003004 avg.loss:  0.550608 ETA:   0h 1m54ss ETA:   0h 0m58s 0.001199 avg.loss:  0.537575 ETA:   0h 0m45s ETA:   0h 0m31sh 0m31s\n",
      "mkdir: cannot create directory ‘result’: File exists\n"
     ]
    }
   ],
   "source": [
    "# modelDef = fasttext.train_unsupervised('data/train_data.txt')\n",
    "modelCbow = fasttext.train_unsupervised('data/train_data.txt', 'cbow')\n",
    "modelSkipgram = fasttext.train_unsupervised('data/train_data.txt', 'skipgram')\n",
    "\n",
    "# Saving different model versions to binary file\n",
    "subprocess.run([\"mkdir\", \"result\"])\n",
    "\n",
    "# modelDef.save_model(\"result/model1.bin\")\n",
    "modelCbow.save_model(\"result/modelCbow.bin\")\n",
    "modelSkipgram.save_model(\"result/modelSkipgram.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSkipgram = fasttext.load_model(\"result/modelSkipgram.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7255551218986511, 'environs'),\n",
       " (0.7216176390647888, 'environment'),\n",
       " (0.7126461863517761, 'encroaches'),\n",
       " (0.7096948027610779, 'human-environment'),\n",
       " (0.6984639167785645, 'environment;'),\n",
       " (0.6963351368904114, 'environs,'),\n",
       " (0.6915313601493835, 'environment,\"'),\n",
       " (0.6869011521339417, 'encroach'),\n",
       " (0.6825509071350098, 'environment)'),\n",
       " (0.6798412203788757, 'encroachment')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSkipgram.get_nearest_neighbors(\"enviromnent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65084994,  0.7445628 , -0.11910941,  0.20016773, -0.10904255,\n",
       "       -0.02735315, -0.40722805,  0.7602869 ,  0.04186199,  0.5296395 ,\n",
       "        0.11413755,  0.21134733, -0.16696438, -0.0735234 ,  0.31618723,\n",
       "        0.18560089, -0.31940514,  0.3650617 ,  0.04022288, -0.24242678,\n",
       "        0.66452146,  0.24958292,  0.03491217, -0.3655611 , -0.11557037,\n",
       "       -0.53072083,  0.4137996 , -0.6410987 ,  0.24087656, -0.2723353 ,\n",
       "        0.4926008 ,  0.48552412, -0.47121677, -0.37111726, -0.21230687,\n",
       "       -0.13511966,  0.17259976, -0.37861803,  0.14162818, -0.4307526 ,\n",
       "        0.7686412 ,  0.1490578 ,  0.8975334 , -0.5342256 ,  0.48184624,\n",
       "       -0.03560356,  0.7507417 , -0.3205803 ,  0.24960923,  0.36136618,\n",
       "       -0.60626477, -0.5483774 , -0.55231214,  0.7599971 ,  0.2439419 ,\n",
       "       -0.02152452, -0.58692247, -0.4081239 , -0.6492689 , -0.82244086,\n",
       "        0.2619828 , -0.4954007 , -0.13332376,  0.30128834,  0.5696984 ,\n",
       "       -0.2193577 , -0.9030422 , -0.33348453, -0.67988   , -0.2830395 ,\n",
       "       -0.50229293,  0.49356088,  1.0049576 ,  0.3194215 , -0.33465976,\n",
       "       -0.5167149 , -0.06780219,  0.18769087, -0.5868039 ,  0.33246017,\n",
       "        0.0095676 , -0.52469957, -1.0032926 ,  0.31598264,  0.31617734,\n",
       "       -0.05461289, -0.15161994, -0.29569086,  0.24567935, -0.26583958,\n",
       "        0.19825357,  0.61964023,  0.25569546,  1.1434906 ,  0.34981596,\n",
       "        0.14460449, -0.5119206 , -0.3477295 , -0.47923678, -0.09738711],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSkipgram.get_word_vector(\"bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkidr\n",
      "(0.6492562890052795, 'minjung')\n",
      "\n",
      "\n",
      "abcd\n",
      "(0.6941401362419128, 'rea,')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model functionality prototype\n",
    "x = \"mkidr abcd\"\n",
    "y = x.split()\n",
    "\n",
    "for char in y:\n",
    "    print(char)\n",
    "    print(modelSkipgram.get_nearest_neighbors(char)[0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65084994  0.7445628  -0.11910941  0.20016773 -0.10904255 -0.02735315\n",
      " -0.40722805  0.7602869   0.04186199  0.5296395   0.11413755  0.21134733\n",
      " -0.16696438 -0.0735234   0.31618723  0.18560089 -0.31940514  0.3650617\n",
      "  0.04022288 -0.24242678  0.66452146  0.24958292  0.03491217 -0.3655611\n",
      " -0.11557037 -0.53072083  0.4137996  -0.6410987   0.24087656 -0.2723353\n",
      "  0.4926008   0.48552412 -0.47121677 -0.37111726 -0.21230687 -0.13511966\n",
      "  0.17259976 -0.37861803  0.14162818 -0.4307526   0.7686412   0.1490578\n",
      "  0.8975334  -0.5342256   0.48184624 -0.03560356  0.7507417  -0.3205803\n",
      "  0.24960923  0.36136618 -0.60626477 -0.5483774  -0.55231214  0.7599971\n",
      "  0.2439419  -0.02152452 -0.58692247 -0.4081239  -0.6492689  -0.82244086\n",
      "  0.2619828  -0.4954007  -0.13332376  0.30128834  0.5696984  -0.2193577\n",
      " -0.9030422  -0.33348453 -0.67988    -0.2830395  -0.50229293  0.49356088\n",
      "  1.0049576   0.3194215  -0.33465976 -0.5167149  -0.06780219  0.18769087\n",
      " -0.5868039   0.33246017  0.0095676  -0.52469957 -1.0032926   0.31598264\n",
      "  0.31617734 -0.05461289 -0.15161994 -0.29569086  0.24567935 -0.26583958\n",
      "  0.19825357  0.61964023  0.25569546  1.1434906   0.34981596  0.14460449\n",
      " -0.5119206  -0.3477295  -0.47923678 -0.09738711]\n"
     ]
    }
   ],
   "source": [
    "# Convert fasttext to tensorflow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the FastText model\n",
    "# fasttext_model = fasttext.load_model(\"your_model.bin\")\n",
    "\n",
    "# Get the vocabulary and embedding dimension\n",
    "words = modelSkipgram.get_words()\n",
    "embedding_dim = modelSkipgram.get_dimension()\n",
    "\n",
    "\n",
    "# Create a dictionary mapping words to their indices\n",
    "word_index = {word: idx for idx, word in enumerate(words)}\n",
    "\n",
    "# Initialize the embedding matrix\n",
    "embedding_matrix = np.zeros((len(words), embedding_dim))\n",
    "\n",
    "# Populate the embedding matrix\n",
    "for word, idx in word_index.items():\n",
    "    embedding_matrix[idx] = modelSkipgram.get_word_vector(word)\n",
    "\n",
    "\n",
    "# Initialize the TensorFlow embedding layer\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=len(words),\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    word_id = word_index.get(word)\n",
    "    if word_id is None:\n",
    "        raise ValueError(f\"Word '{word}' not in vocabulary.\")\n",
    "    return embedding_layer(tf.constant([word_id]))[0].numpy()\n",
    "\n",
    "# Example usage\n",
    "word_vector = get_word_embedding(\"bot\")\n",
    "print(word_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-ySdPZ147-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
